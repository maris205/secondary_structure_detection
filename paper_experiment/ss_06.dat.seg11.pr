Segmenting ss_06.dat.seg11 using 1-gram model
Boundary initialization: ran
Unigram generator: monkeys
 alpha0: 20, p_boundary: 0.5
Sampling of hyperparameters: OFF
Phoneme distribution: uniform
Sampling 1000 iterations
evaluating a sample
random seed = 1401863024
alphabet size = 22
Raising temperature in 10 increments: (0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1)

Reference lexicon summary:

Total words of each length (token/type): 
1: 738718 (31.4543%) / 22 (0.00661993%)
2: 701460 (29.8679%) / 406 (0.122168%)
3: 297780 (12.6794%) / 7916 (2.38197%)
4: 271915 (11.578%) / 63533 (19.1174%)
5: 125664 (5.35072%) / 64163 (19.307%)
6: 61664 (2.62563%) / 54424 (16.3765%)
7: 42017 (1.78907%) / 40156 (12.0832%)
8: 33693 (1.43463%) / 32007 (9.63109%)
9: 28343 (1.20683%) / 26020 (7.82957%)
10: 24803 (1.0561%) / 23996 (7.22053%)
11: 22486 (0.957445%) / 19687 (5.92393%)
Average word length: 2.74003 / 6.48126

Segmented lexicon summary:

Total words of each length (token/type): 
1: 1548767 (43.1959%) / 22 (0.493052%)
2: 1322300 (36.8797%) / 383 (8.58359%)
3: 667671 (18.6217%) / 3450 (77.3196%)
4: 33814 (0.943091%) / 482 (10.8023%)
5: 1173 (0.0327156%) / 24 (0.537875%)
6: 2173 (0.0606061%) / 20 (0.448229%)
7: 2006 (0.0559484%) / 30 (0.672344%)
8: 3179 (0.088664%) / 23 (0.515464%)
9: 560 (0.0156187%) / 12 (0.268938%)
10: 2200 (0.0613592%) / 7 (0.15688%)
11: 1257 (0.0350584%) / 3 (0.0672344%)
12: 341 (0.00951067%) / 2 (0.0448229%)
14: 1 (2.78905e-05%) / 1 (0.0224115%)
18: 1 (2.78905e-05%) / 1 (0.0224115%)
27: 1 (2.78905e-05%) / 1 (0.0224115%)
37: 1 (2.78905e-05%) / 1 (0.0224115%)
Average word length: 1.79478 / 3.14455

P 9.939 R 15.17 F 12.01 BP 36.57 BR 56.02 BF 44.25 LP 96.84 LR 1.3 LF 2.566
p_cont=0.993476, log prob = -2.1764e+07
