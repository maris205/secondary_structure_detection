Segmenting ss_06.dat.seg12 using 1-gram model
Boundary initialization: ran
Unigram generator: monkeys
 alpha0: 20, p_boundary: 0.5
Sampling of hyperparameters: OFF
Phoneme distribution: uniform
Sampling 1000 iterations
evaluating a sample
random seed = 1401877344
alphabet size = 22
Raising temperature in 10 increments: (0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1)

Reference lexicon summary:

Total words of each length (token/type): 
1: 724860 (31.6029%) / 22 (0.00631578%)
2: 677724 (29.5478%) / 406 (0.116555%)
3: 288488 (12.5777%) / 7916 (2.27253%)
4: 254768 (11.1075%) / 63533 (18.2391%)
5: 119673 (5.21758%) / 64163 (18.42%)
6: 61103 (2.66401%) / 54424 (15.6241%)
7: 41905 (1.827%) / 40156 (11.528%)
8: 33628 (1.46613%) / 32007 (9.18859%)
9: 28154 (1.22748%) / 26020 (7.46984%)
10: 24731 (1.07824%) / 23996 (6.88879%)
11: 21206 (0.924553%) / 19687 (5.65176%)
12: 17410 (0.759052%) / 16004 (4.59444%)
Average word length: 2.8056 / 6.73482

Segmented lexicon summary:

Total words of each length (token/type): 
1: 1589655 (44.1137%) / 22 (0.490962%)
2: 1293394 (35.8923%) / 384 (8.56952%)
3: 674213 (18.7097%) / 3448 (76.9471%)
4: 33084 (0.918097%) / 481 (10.7342%)
5: 1554 (0.0431242%) / 31 (0.69181%)
6: 2157 (0.0598578%) / 23 (0.513278%)
7: 1991 (0.0552512%) / 38 (0.848025%)
8: 3161 (0.0877193%) / 21 (0.468645%)
9: 769 (0.0213401%) / 15 (0.334747%)
10: 2431 (0.0674614%) / 12 (0.267797%)
11: 1129 (0.0313303%) / 3 (0.0669493%)
15: 1 (2.77505e-05%) / 1 (0.0223164%)
23: 1 (2.77505e-05%) / 1 (0.0223164%)
25: 1 (2.77505e-05%) / 1 (0.0223164%)
Average word length: 1.78576 / 3.15465

P 9.735 R 15.29 F 11.9 BP 35.77 BR 56.41 BF 43.78 LP 96.45 LR 1.241 LF 2.45
p_cont=0.993509, log prob = -2.17739e+07
